{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in ./.venv/lib/python3.9/site-packages (2.18.0)\n",
      "Requirement already satisfied: pillow in ./.venv/lib/python3.9/site-packages (11.0.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.9/site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.9/site-packages (3.9.3)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp39-cp39-macosx_12_0_arm64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./.venv/lib/python3.9/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./.venv/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./.venv/lib/python3.9/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./.venv/lib/python3.9/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./.venv/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./.venv/lib/python3.9/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./.venv/lib/python3.9/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.9/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in ./.venv/lib/python3.9/site-packages (from tensorflow) (5.29.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./.venv/lib/python3.9/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.9/site-packages (from tensorflow) (58.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.9/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./.venv/lib/python3.9/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./.venv/lib/python3.9/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./.venv/lib/python3.9/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.venv/lib/python3.9/site-packages (from tensorflow) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in ./.venv/lib/python3.9/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in ./.venv/lib/python3.9/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in ./.venv/lib/python3.9/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in ./.venv/lib/python3.9/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./.venv/lib/python3.9/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.9/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.9/site-packages (from matplotlib) (4.55.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.9/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./.venv/lib/python3.9/site-packages (from matplotlib) (6.4.5)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.venv/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./.venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.21.0)\n",
      "Requirement already satisfied: rich in ./.venv/lib/python3.9/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in ./.venv/lib/python3.9/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in ./.venv/lib/python3.9/site-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.venv/lib/python3.9/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.venv/lib/python3.9/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.venv/lib/python3.9/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in ./.venv/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow) (8.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.venv/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.9/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.9/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Downloading scikit_learn-1.5.2-cp39-cp39-macosx_12_0_arm64.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl (30.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.3/30.3 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.2 scipy-1.13.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow pillow numpy matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Found 8000 valid images\n",
      "Total images found: 8000\n",
      "Training samples: 6400\n",
      "Validation samples: 1600\n",
      "Creating model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_14       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ activation_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_15       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ activation_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │ activation_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_16       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_6 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_17       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ activation_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ conv2d_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_18       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_7     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_7 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_19       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ conv2d_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_20       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_8     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_8 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ spatial_dropout2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,146,752</span> │ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ char_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">13,851</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ char_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">13,851</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ char_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">13,851</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ char_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">13,851</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m65\u001b[0m,    │        \u001b[38;5;34m320\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m65\u001b[0m,    │        \u001b[38;5;34m128\u001b[0m │ conv2d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_14       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m65\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m65\u001b[0m,    │      \u001b[38;5;34m9,248\u001b[0m │ activation_14[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m65\u001b[0m,    │        \u001b[38;5;34m128\u001b[0m │ conv2d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_15       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m65\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m65\u001b[0m,    │      \u001b[38;5;34m9,248\u001b[0m │ activation_15[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m65\u001b[0m,    │        \u001b[38;5;34m128\u001b[0m │ conv2d_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_6 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m65\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │ activation_14[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_16       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m65\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ activation_16[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_6 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_6[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │     \u001b[38;5;34m18,496\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_17       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ activation_17[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │      \u001b[38;5;34m2,112\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_7 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │ conv2d_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_18       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_7     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ activation_18[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_7 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_7[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_25 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m16\u001b[0m,     │     \u001b[38;5;34m73,856\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m16\u001b[0m,     │        \u001b[38;5;34m512\u001b[0m │ conv2d_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_19       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m16\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_26 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m16\u001b[0m,     │    \u001b[38;5;34m147,584\u001b[0m │ activation_19[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m16\u001b[0m,     │        \u001b[38;5;34m512\u001b[0m │ conv2d_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_24 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m16\u001b[0m,     │      \u001b[38;5;34m8,320\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_8 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m16\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │ conv2d_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_20       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m16\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ add_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_8     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ activation_20[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_8 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_8[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ spatial_dropout2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │  \u001b[38;5;34m3,146,752\u001b[0m │ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │      \u001b[38;5;34m4,096\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m524,800\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ char_0 (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m)        │     \u001b[38;5;34m13,851\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ char_1 (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m)        │     \u001b[38;5;34m13,851\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ char_2 (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m)        │     \u001b[38;5;34m13,851\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ char_3 (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m)        │     \u001b[38;5;34m13,851\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,041,132</span> (15.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,041,132\u001b[0m (15.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,037,100</span> (15.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,037,100\u001b[0m (15.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,032</span> (15.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,032\u001b[0m (15.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Epoch 1/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 101ms/step - char_0_accuracy: 0.1117 - char_0_loss: 3.7028 - char_0_precision: 0.1968 - char_0_recall: 0.0304 - char_1_accuracy: 0.0617 - char_1_loss: 3.9580 - char_1_precision_1: 0.0844 - char_1_recall_1: 0.0070 - char_2_accuracy: 0.0637 - char_2_loss: 3.9809 - char_2_precision_2: 0.0878 - char_2_recall_2: 0.0077 - char_3_accuracy: 0.0718 - char_3_loss: 3.9049 - char_3_precision_3: 0.1263 - char_3_recall_3: 0.0125 - loss: 15.5465 - val_char_0_accuracy: 0.0969 - val_char_0_loss: 5.3441 - val_char_0_precision: 0.0947 - val_char_0_recall: 0.0894 - val_char_1_accuracy: 0.0819 - val_char_1_loss: 4.1581 - val_char_1_precision_1: 0.0000e+00 - val_char_1_recall_1: 0.0000e+00 - val_char_2_accuracy: 0.1019 - val_char_2_loss: 4.6784 - val_char_2_precision_2: 0.6250 - val_char_2_recall_2: 0.0063 - val_char_3_accuracy: 0.0900 - val_char_3_loss: 3.8999 - val_char_3_precision_3: 1.0000 - val_char_3_recall_3: 0.0012 - val_loss: 18.0805 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 102ms/step - char_0_accuracy: 0.6917 - char_0_loss: 0.9478 - char_0_precision: 0.8046 - char_0_recall: 0.5831 - char_1_accuracy: 0.4615 - char_1_loss: 1.7042 - char_1_precision_1: 0.6655 - char_1_recall_1: 0.2640 - char_2_accuracy: 0.4591 - char_2_loss: 1.7239 - char_2_precision_2: 0.6544 - char_2_recall_2: 0.2629 - char_3_accuracy: 0.5532 - char_3_loss: 1.3766 - char_3_precision_3: 0.7054 - char_3_recall_3: 0.3694 - loss: 5.7525 - val_char_0_accuracy: 0.6988 - val_char_0_loss: 0.8814 - val_char_0_precision: 0.8040 - val_char_0_recall: 0.6000 - val_char_1_accuracy: 0.6087 - val_char_1_loss: 1.2235 - val_char_1_precision_1: 0.7846 - val_char_1_recall_1: 0.4462 - val_char_2_accuracy: 0.5825 - val_char_2_loss: 1.2199 - val_char_2_precision_2: 0.7358 - val_char_2_recall_2: 0.4387 - val_char_3_accuracy: 0.6100 - val_char_3_loss: 1.1645 - val_char_3_precision_3: 0.7279 - val_char_3_recall_3: 0.4631 - val_loss: 4.4892 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 111ms/step - char_0_accuracy: 0.9318 - char_0_loss: 0.2237 - char_0_precision: 0.9503 - char_0_recall: 0.9053 - char_1_accuracy: 0.8353 - char_1_loss: 0.5230 - char_1_precision_1: 0.9051 - char_1_recall_1: 0.7701 - char_2_accuracy: 0.8272 - char_2_loss: 0.5470 - char_2_precision_2: 0.8955 - char_2_recall_2: 0.7414 - char_3_accuracy: 0.8663 - char_3_loss: 0.4273 - char_3_precision_3: 0.9172 - char_3_recall_3: 0.8080 - loss: 1.7210 - val_char_0_accuracy: 0.9894 - val_char_0_loss: 0.0497 - val_char_0_precision: 0.9943 - val_char_0_recall: 0.9875 - val_char_1_accuracy: 0.9400 - val_char_1_loss: 0.1915 - val_char_1_precision_1: 0.9593 - val_char_1_recall_1: 0.9275 - val_char_2_accuracy: 0.9431 - val_char_2_loss: 0.1783 - val_char_2_precision_2: 0.9587 - val_char_2_recall_2: 0.9294 - val_char_3_accuracy: 0.9631 - val_char_3_loss: 0.1361 - val_char_3_precision_3: 0.9719 - val_char_3_recall_3: 0.9506 - val_loss: 0.5557 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 106ms/step - char_0_accuracy: 0.9695 - char_0_loss: 0.1123 - char_0_precision: 0.9772 - char_0_recall: 0.9581 - char_1_accuracy: 0.9362 - char_1_loss: 0.2305 - char_1_precision_1: 0.9551 - char_1_recall_1: 0.9101 - char_2_accuracy: 0.9237 - char_2_loss: 0.2424 - char_2_precision_2: 0.9448 - char_2_recall_2: 0.9012 - char_3_accuracy: 0.9440 - char_3_loss: 0.1979 - char_3_precision_3: 0.9590 - char_3_recall_3: 0.9203 - loss: 0.7831 - val_char_0_accuracy: 0.9894 - val_char_0_loss: 0.0392 - val_char_0_precision: 0.9918 - val_char_0_recall: 0.9856 - val_char_1_accuracy: 0.9650 - val_char_1_loss: 0.1134 - val_char_1_precision_1: 0.9709 - val_char_1_recall_1: 0.9600 - val_char_2_accuracy: 0.9569 - val_char_2_loss: 0.1256 - val_char_2_precision_2: 0.9663 - val_char_2_recall_2: 0.9500 - val_char_3_accuracy: 0.9725 - val_char_3_loss: 0.1050 - val_char_3_precision_3: 0.9766 - val_char_3_recall_3: 0.9650 - val_loss: 0.3831 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 110ms/step - char_0_accuracy: 0.9833 - char_0_loss: 0.0668 - char_0_precision: 0.9849 - char_0_recall: 0.9803 - char_1_accuracy: 0.9597 - char_1_loss: 0.1317 - char_1_precision_1: 0.9712 - char_1_recall_1: 0.9521 - char_2_accuracy: 0.9549 - char_2_loss: 0.1510 - char_2_precision_2: 0.9687 - char_2_recall_2: 0.9434 - char_3_accuracy: 0.9630 - char_3_loss: 0.1289 - char_3_precision_3: 0.9730 - char_3_recall_3: 0.9519 - loss: 0.4784 - val_char_0_accuracy: 0.9937 - val_char_0_loss: 0.0279 - val_char_0_precision: 0.9950 - val_char_0_recall: 0.9925 - val_char_1_accuracy: 0.9731 - val_char_1_loss: 0.0872 - val_char_1_precision_1: 0.9767 - val_char_1_recall_1: 0.9694 - val_char_2_accuracy: 0.9750 - val_char_2_loss: 0.0826 - val_char_2_precision_2: 0.9785 - val_char_2_recall_2: 0.9681 - val_char_3_accuracy: 0.9887 - val_char_3_loss: 0.0486 - val_char_3_precision_3: 0.9906 - val_char_3_recall_3: 0.9837 - val_loss: 0.2463 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 110ms/step - char_0_accuracy: 0.9868 - char_0_loss: 0.0464 - char_0_precision: 0.9886 - char_0_recall: 0.9839 - char_1_accuracy: 0.9756 - char_1_loss: 0.0908 - char_1_precision_1: 0.9813 - char_1_recall_1: 0.9679 - char_2_accuracy: 0.9641 - char_2_loss: 0.1122 - char_2_precision_2: 0.9733 - char_2_recall_2: 0.9568 - char_3_accuracy: 0.9747 - char_3_loss: 0.0855 - char_3_precision_3: 0.9793 - char_3_recall_3: 0.9709 - loss: 0.3350 - val_char_0_accuracy: 0.9994 - val_char_0_loss: 0.0101 - val_char_0_precision: 0.9994 - val_char_0_recall: 0.9987 - val_char_1_accuracy: 0.9819 - val_char_1_loss: 0.0643 - val_char_1_precision_1: 0.9824 - val_char_1_recall_1: 0.9787 - val_char_2_accuracy: 0.9881 - val_char_2_loss: 0.0437 - val_char_2_precision_2: 0.9918 - val_char_2_recall_2: 0.9862 - val_char_3_accuracy: 0.9925 - val_char_3_loss: 0.0295 - val_char_3_precision_3: 0.9931 - val_char_3_recall_3: 0.9906 - val_loss: 0.1476 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 114ms/step - char_0_accuracy: 0.9884 - char_0_loss: 0.0372 - char_0_precision: 0.9912 - char_0_recall: 0.9867 - char_1_accuracy: 0.9796 - char_1_loss: 0.0722 - char_1_precision_1: 0.9828 - char_1_recall_1: 0.9766 - char_2_accuracy: 0.9742 - char_2_loss: 0.0874 - char_2_precision_2: 0.9788 - char_2_recall_2: 0.9669 - char_3_accuracy: 0.9787 - char_3_loss: 0.0654 - char_3_precision_3: 0.9819 - char_3_recall_3: 0.9751 - loss: 0.2622 - val_char_0_accuracy: 0.9987 - val_char_0_loss: 0.0067 - val_char_0_precision: 0.9987 - val_char_0_recall: 0.9987 - val_char_1_accuracy: 0.9656 - val_char_1_loss: 0.1040 - val_char_1_precision_1: 0.9698 - val_char_1_recall_1: 0.9631 - val_char_2_accuracy: 0.9831 - val_char_2_loss: 0.0456 - val_char_2_precision_2: 0.9862 - val_char_2_recall_2: 0.9812 - val_char_3_accuracy: 0.9794 - val_char_3_loss: 0.0557 - val_char_3_precision_3: 0.9837 - val_char_3_recall_3: 0.9781 - val_loss: 0.2120 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 115ms/step - char_0_accuracy: 0.9905 - char_0_loss: 0.0326 - char_0_precision: 0.9915 - char_0_recall: 0.9884 - char_1_accuracy: 0.9817 - char_1_loss: 0.0591 - char_1_precision_1: 0.9844 - char_1_recall_1: 0.9781 - char_2_accuracy: 0.9798 - char_2_loss: 0.0635 - char_2_precision_2: 0.9826 - char_2_recall_2: 0.9752 - char_3_accuracy: 0.9878 - char_3_loss: 0.0527 - char_3_precision_3: 0.9897 - char_3_recall_3: 0.9854 - loss: 0.2079 - val_char_0_accuracy: 0.9981 - val_char_0_loss: 0.0053 - val_char_0_precision: 0.9981 - val_char_0_recall: 0.9975 - val_char_1_accuracy: 0.9912 - val_char_1_loss: 0.0269 - val_char_1_precision_1: 0.9931 - val_char_1_recall_1: 0.9906 - val_char_2_accuracy: 0.9887 - val_char_2_loss: 0.0359 - val_char_2_precision_2: 0.9894 - val_char_2_recall_2: 0.9875 - val_char_3_accuracy: 0.9962 - val_char_3_loss: 0.0177 - val_char_3_precision_3: 0.9962 - val_char_3_recall_3: 0.9956 - val_loss: 0.0857 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 122ms/step - char_0_accuracy: 0.9925 - char_0_loss: 0.0281 - char_0_precision: 0.9940 - char_0_recall: 0.9909 - char_1_accuracy: 0.9865 - char_1_loss: 0.0461 - char_1_precision_1: 0.9904 - char_1_recall_1: 0.9817 - char_2_accuracy: 0.9847 - char_2_loss: 0.0510 - char_2_precision_2: 0.9884 - char_2_recall_2: 0.9826 - char_3_accuracy: 0.9887 - char_3_loss: 0.0458 - char_3_precision_3: 0.9902 - char_3_recall_3: 0.9848 - loss: 0.1710 - val_char_0_accuracy: 0.9975 - val_char_0_loss: 0.0118 - val_char_0_precision: 0.9981 - val_char_0_recall: 0.9975 - val_char_1_accuracy: 0.9894 - val_char_1_loss: 0.0356 - val_char_1_precision_1: 0.9925 - val_char_1_recall_1: 0.9881 - val_char_2_accuracy: 0.9862 - val_char_2_loss: 0.0405 - val_char_2_precision_2: 0.9899 - val_char_2_recall_2: 0.9850 - val_char_3_accuracy: 0.9919 - val_char_3_loss: 0.0290 - val_char_3_precision_3: 0.9925 - val_char_3_recall_3: 0.9919 - val_loss: 0.1169 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 119ms/step - char_0_accuracy: 0.9945 - char_0_loss: 0.0180 - char_0_precision: 0.9948 - char_0_recall: 0.9942 - char_1_accuracy: 0.9904 - char_1_loss: 0.0351 - char_1_precision_1: 0.9912 - char_1_recall_1: 0.9894 - char_2_accuracy: 0.9864 - char_2_loss: 0.0402 - char_2_precision_2: 0.9887 - char_2_recall_2: 0.9831 - char_3_accuracy: 0.9889 - char_3_loss: 0.0439 - char_3_precision_3: 0.9903 - char_3_recall_3: 0.9875 - loss: 0.1371 - val_char_0_accuracy: 0.9994 - val_char_0_loss: 0.0042 - val_char_0_precision: 0.9994 - val_char_0_recall: 0.9987 - val_char_1_accuracy: 0.9937 - val_char_1_loss: 0.0187 - val_char_1_precision_1: 0.9962 - val_char_1_recall_1: 0.9937 - val_char_2_accuracy: 0.9887 - val_char_2_loss: 0.0345 - val_char_2_precision_2: 0.9900 - val_char_2_recall_2: 0.9881 - val_char_3_accuracy: 0.9962 - val_char_3_loss: 0.0173 - val_char_3_precision_3: 0.9969 - val_char_3_recall_3: 0.9956 - val_loss: 0.0747 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 116ms/step - char_0_accuracy: 0.9948 - char_0_loss: 0.0170 - char_0_precision: 0.9951 - char_0_recall: 0.9943 - char_1_accuracy: 0.9895 - char_1_loss: 0.0317 - char_1_precision_1: 0.9914 - char_1_recall_1: 0.9885 - char_2_accuracy: 0.9904 - char_2_loss: 0.0335 - char_2_precision_2: 0.9924 - char_2_recall_2: 0.9898 - char_3_accuracy: 0.9913 - char_3_loss: 0.0277 - char_3_precision_3: 0.9932 - char_3_recall_3: 0.9905 - loss: 0.1099 - val_char_0_accuracy: 0.9969 - val_char_0_loss: 0.0094 - val_char_0_precision: 0.9975 - val_char_0_recall: 0.9969 - val_char_1_accuracy: 0.9925 - val_char_1_loss: 0.0300 - val_char_1_precision_1: 0.9937 - val_char_1_recall_1: 0.9919 - val_char_2_accuracy: 0.9937 - val_char_2_loss: 0.0234 - val_char_2_precision_2: 0.9937 - val_char_2_recall_2: 0.9906 - val_char_3_accuracy: 0.9956 - val_char_3_loss: 0.0151 - val_char_3_precision_3: 0.9969 - val_char_3_recall_3: 0.9956 - val_loss: 0.0779 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 114ms/step - char_0_accuracy: 0.9959 - char_0_loss: 0.0149 - char_0_precision: 0.9965 - char_0_recall: 0.9956 - char_1_accuracy: 0.9925 - char_1_loss: 0.0251 - char_1_precision_1: 0.9932 - char_1_recall_1: 0.9919 - char_2_accuracy: 0.9939 - char_2_loss: 0.0265 - char_2_precision_2: 0.9954 - char_2_recall_2: 0.9922 - char_3_accuracy: 0.9934 - char_3_loss: 0.0255 - char_3_precision_3: 0.9941 - char_3_recall_3: 0.9901 - loss: 0.0920 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 9.7809e-04 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9962 - val_char_1_loss: 0.0165 - val_char_1_precision_1: 0.9975 - val_char_1_recall_1: 0.9962 - val_char_2_accuracy: 0.9925 - val_char_2_loss: 0.0278 - val_char_2_precision_2: 0.9931 - val_char_2_recall_2: 0.9919 - val_char_3_accuracy: 0.9956 - val_char_3_loss: 0.0156 - val_char_3_precision_3: 0.9962 - val_char_3_recall_3: 0.9956 - val_loss: 0.0609 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 117ms/step - char_0_accuracy: 0.9953 - char_0_loss: 0.0154 - char_0_precision: 0.9955 - char_0_recall: 0.9945 - char_1_accuracy: 0.9949 - char_1_loss: 0.0185 - char_1_precision_1: 0.9952 - char_1_recall_1: 0.9943 - char_2_accuracy: 0.9913 - char_2_loss: 0.0242 - char_2_precision_2: 0.9921 - char_2_recall_2: 0.9907 - char_3_accuracy: 0.9907 - char_3_loss: 0.0251 - char_3_precision_3: 0.9909 - char_3_recall_3: 0.9904 - loss: 0.0832 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 0.0011 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9962 - val_char_1_loss: 0.0243 - val_char_1_precision_1: 0.9962 - val_char_1_recall_1: 0.9962 - val_char_2_accuracy: 0.9925 - val_char_2_loss: 0.0205 - val_char_2_precision_2: 0.9925 - val_char_2_recall_2: 0.9912 - val_char_3_accuracy: 0.9975 - val_char_3_loss: 0.0122 - val_char_3_precision_3: 0.9981 - val_char_3_recall_3: 0.9975 - val_loss: 0.0580 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 120ms/step - char_0_accuracy: 0.9970 - char_0_loss: 0.0103 - char_0_precision: 0.9979 - char_0_recall: 0.9966 - char_1_accuracy: 0.9908 - char_1_loss: 0.0264 - char_1_precision_1: 0.9916 - char_1_recall_1: 0.9893 - char_2_accuracy: 0.9945 - char_2_loss: 0.0249 - char_2_precision_2: 0.9950 - char_2_recall_2: 0.9941 - char_3_accuracy: 0.9946 - char_3_loss: 0.0192 - char_3_precision_3: 0.9958 - char_3_recall_3: 0.9939 - loss: 0.0808 - val_char_0_accuracy: 0.9981 - val_char_0_loss: 0.0100 - val_char_0_precision: 0.9981 - val_char_0_recall: 0.9981 - val_char_1_accuracy: 0.9931 - val_char_1_loss: 0.0320 - val_char_1_precision_1: 0.9931 - val_char_1_recall_1: 0.9919 - val_char_2_accuracy: 0.9912 - val_char_2_loss: 0.0248 - val_char_2_precision_2: 0.9919 - val_char_2_recall_2: 0.9912 - val_char_3_accuracy: 0.9919 - val_char_3_loss: 0.0295 - val_char_3_precision_3: 0.9937 - val_char_3_recall_3: 0.9912 - val_loss: 0.0963 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 120ms/step - char_0_accuracy: 0.9963 - char_0_loss: 0.0124 - char_0_precision: 0.9968 - char_0_recall: 0.9957 - char_1_accuracy: 0.9928 - char_1_loss: 0.0221 - char_1_precision_1: 0.9937 - char_1_recall_1: 0.9924 - char_2_accuracy: 0.9924 - char_2_loss: 0.0236 - char_2_precision_2: 0.9939 - char_2_recall_2: 0.9921 - char_3_accuracy: 0.9918 - char_3_loss: 0.0220 - char_3_precision_3: 0.9935 - char_3_recall_3: 0.9912 - loss: 0.0801 - val_char_0_accuracy: 0.9994 - val_char_0_loss: 0.0027 - val_char_0_precision: 0.9994 - val_char_0_recall: 0.9994 - val_char_1_accuracy: 0.9912 - val_char_1_loss: 0.0305 - val_char_1_precision_1: 0.9919 - val_char_1_recall_1: 0.9912 - val_char_2_accuracy: 0.9950 - val_char_2_loss: 0.0139 - val_char_2_precision_2: 0.9950 - val_char_2_recall_2: 0.9950 - val_char_3_accuracy: 0.9944 - val_char_3_loss: 0.0219 - val_char_3_precision_3: 0.9950 - val_char_3_recall_3: 0.9944 - val_loss: 0.0690 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 116ms/step - char_0_accuracy: 0.9976 - char_0_loss: 0.0104 - char_0_precision: 0.9980 - char_0_recall: 0.9972 - char_1_accuracy: 0.9918 - char_1_loss: 0.0244 - char_1_precision_1: 0.9939 - char_1_recall_1: 0.9907 - char_2_accuracy: 0.9900 - char_2_loss: 0.0266 - char_2_precision_2: 0.9918 - char_2_recall_2: 0.9889 - char_3_accuracy: 0.9949 - char_3_loss: 0.0211 - char_3_precision_3: 0.9964 - char_3_recall_3: 0.9940 - loss: 0.0824 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 0.0015 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9944 - val_char_1_loss: 0.0199 - val_char_1_precision_1: 0.9944 - val_char_1_recall_1: 0.9944 - val_char_2_accuracy: 0.9912 - val_char_2_loss: 0.0245 - val_char_2_precision_2: 0.9925 - val_char_2_recall_2: 0.9906 - val_char_3_accuracy: 0.9975 - val_char_3_loss: 0.0110 - val_char_3_precision_3: 0.9975 - val_char_3_recall_3: 0.9969 - val_loss: 0.0570 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 116ms/step - char_0_accuracy: 0.9986 - char_0_loss: 0.0079 - char_0_precision: 0.9988 - char_0_recall: 0.9985 - char_1_accuracy: 0.9934 - char_1_loss: 0.0215 - char_1_precision_1: 0.9946 - char_1_recall_1: 0.9923 - char_2_accuracy: 0.9939 - char_2_loss: 0.0209 - char_2_precision_2: 0.9945 - char_2_recall_2: 0.9931 - char_3_accuracy: 0.9937 - char_3_loss: 0.0192 - char_3_precision_3: 0.9941 - char_3_recall_3: 0.9931 - loss: 0.0695 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 5.9128e-04 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9950 - val_char_1_loss: 0.0251 - val_char_1_precision_1: 0.9956 - val_char_1_recall_1: 0.9944 - val_char_2_accuracy: 0.9944 - val_char_2_loss: 0.0239 - val_char_2_precision_2: 0.9944 - val_char_2_recall_2: 0.9944 - val_char_3_accuracy: 0.9950 - val_char_3_loss: 0.0096 - val_char_3_precision_3: 0.9950 - val_char_3_recall_3: 0.9950 - val_loss: 0.0593 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 116ms/step - char_0_accuracy: 0.9982 - char_0_loss: 0.0067 - char_0_precision: 0.9983 - char_0_recall: 0.9979 - char_1_accuracy: 0.9966 - char_1_loss: 0.0152 - char_1_precision_1: 0.9966 - char_1_recall_1: 0.9955 - char_2_accuracy: 0.9942 - char_2_loss: 0.0163 - char_2_precision_2: 0.9948 - char_2_recall_2: 0.9937 - char_3_accuracy: 0.9955 - char_3_loss: 0.0172 - char_3_precision_3: 0.9965 - char_3_recall_3: 0.9949 - loss: 0.0553 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 0.0010 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9969 - val_char_1_loss: 0.0155 - val_char_1_precision_1: 0.9969 - val_char_1_recall_1: 0.9969 - val_char_2_accuracy: 0.9950 - val_char_2_loss: 0.0186 - val_char_2_precision_2: 0.9950 - val_char_2_recall_2: 0.9950 - val_char_3_accuracy: 0.9950 - val_char_3_loss: 0.0130 - val_char_3_precision_3: 0.9956 - val_char_3_recall_3: 0.9950 - val_loss: 0.0482 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 115ms/step - char_0_accuracy: 0.9980 - char_0_loss: 0.0070 - char_0_precision: 0.9982 - char_0_recall: 0.9979 - char_1_accuracy: 0.9958 - char_1_loss: 0.0139 - char_1_precision_1: 0.9963 - char_1_recall_1: 0.9954 - char_2_accuracy: 0.9960 - char_2_loss: 0.0145 - char_2_precision_2: 0.9972 - char_2_recall_2: 0.9955 - char_3_accuracy: 0.9966 - char_3_loss: 0.0119 - char_3_precision_3: 0.9967 - char_3_recall_3: 0.9948 - loss: 0.0473 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 7.8654e-04 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9962 - val_char_1_loss: 0.0139 - val_char_1_precision_1: 0.9969 - val_char_1_recall_1: 0.9962 - val_char_2_accuracy: 0.9937 - val_char_2_loss: 0.0190 - val_char_2_precision_2: 0.9944 - val_char_2_recall_2: 0.9931 - val_char_3_accuracy: 0.9981 - val_char_3_loss: 0.0092 - val_char_3_precision_3: 0.9981 - val_char_3_recall_3: 0.9981 - val_loss: 0.0429 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 117ms/step - char_0_accuracy: 0.9986 - char_0_loss: 0.0063 - char_0_precision: 0.9987 - char_0_recall: 0.9986 - char_1_accuracy: 0.9974 - char_1_loss: 0.0127 - char_1_precision_1: 0.9982 - char_1_recall_1: 0.9967 - char_2_accuracy: 0.9969 - char_2_loss: 0.0146 - char_2_precision_2: 0.9970 - char_2_recall_2: 0.9947 - char_3_accuracy: 0.9971 - char_3_loss: 0.0113 - char_3_precision_3: 0.9980 - char_3_recall_3: 0.9965 - loss: 0.0449 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 8.2389e-04 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9931 - val_char_1_loss: 0.0251 - val_char_1_precision_1: 0.9931 - val_char_1_recall_1: 0.9925 - val_char_2_accuracy: 0.9919 - val_char_2_loss: 0.0248 - val_char_2_precision_2: 0.9925 - val_char_2_recall_2: 0.9912 - val_char_3_accuracy: 0.9912 - val_char_3_loss: 0.0201 - val_char_3_precision_3: 0.9912 - val_char_3_recall_3: 0.9906 - val_loss: 0.0709 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 116ms/step - char_0_accuracy: 0.9990 - char_0_loss: 0.0054 - char_0_precision: 0.9994 - char_0_recall: 0.9990 - char_1_accuracy: 0.9959 - char_1_loss: 0.0126 - char_1_precision_1: 0.9965 - char_1_recall_1: 0.9952 - char_2_accuracy: 0.9942 - char_2_loss: 0.0150 - char_2_precision_2: 0.9949 - char_2_recall_2: 0.9938 - char_3_accuracy: 0.9981 - char_3_loss: 0.0083 - char_3_precision_3: 0.9985 - char_3_recall_3: 0.9979 - loss: 0.0413 - val_char_0_accuracy: 0.9994 - val_char_0_loss: 0.0014 - val_char_0_precision: 0.9994 - val_char_0_recall: 0.9994 - val_char_1_accuracy: 0.9969 - val_char_1_loss: 0.0140 - val_char_1_precision_1: 0.9969 - val_char_1_recall_1: 0.9962 - val_char_2_accuracy: 0.9950 - val_char_2_loss: 0.0155 - val_char_2_precision_2: 0.9950 - val_char_2_recall_2: 0.9950 - val_char_3_accuracy: 0.9950 - val_char_3_loss: 0.0156 - val_char_3_precision_3: 0.9950 - val_char_3_recall_3: 0.9950 - val_loss: 0.0466 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 117ms/step - char_0_accuracy: 0.9981 - char_0_loss: 0.0061 - char_0_precision: 0.9983 - char_0_recall: 0.9980 - char_1_accuracy: 0.9984 - char_1_loss: 0.0078 - char_1_precision_1: 0.9984 - char_1_recall_1: 0.9980 - char_2_accuracy: 0.9983 - char_2_loss: 0.0075 - char_2_precision_2: 0.9983 - char_2_recall_2: 0.9983 - char_3_accuracy: 0.9973 - char_3_loss: 0.0092 - char_3_precision_3: 0.9976 - char_3_recall_3: 0.9971 - loss: 0.0306 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 2.5161e-04 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9937 - val_char_1_loss: 0.0258 - val_char_1_precision_1: 0.9937 - val_char_1_recall_1: 0.9931 - val_char_2_accuracy: 0.9937 - val_char_2_loss: 0.0152 - val_char_2_precision_2: 0.9937 - val_char_2_recall_2: 0.9937 - val_char_3_accuracy: 0.9944 - val_char_3_loss: 0.0164 - val_char_3_precision_3: 0.9950 - val_char_3_recall_3: 0.9937 - val_loss: 0.0576 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 118ms/step - char_0_accuracy: 0.9988 - char_0_loss: 0.0050 - char_0_precision: 0.9990 - char_0_recall: 0.9988 - char_1_accuracy: 0.9983 - char_1_loss: 0.0070 - char_1_precision_1: 0.9983 - char_1_recall_1: 0.9982 - char_2_accuracy: 0.9976 - char_2_loss: 0.0100 - char_2_precision_2: 0.9984 - char_2_recall_2: 0.9972 - char_3_accuracy: 0.9973 - char_3_loss: 0.0084 - char_3_precision_3: 0.9973 - char_3_recall_3: 0.9973 - loss: 0.0304 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 1.6965e-04 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9956 - val_char_1_loss: 0.0132 - val_char_1_precision_1: 0.9956 - val_char_1_recall_1: 0.9956 - val_char_2_accuracy: 0.9981 - val_char_2_loss: 0.0049 - val_char_2_precision_2: 0.9987 - val_char_2_recall_2: 0.9981 - val_char_3_accuracy: 0.9950 - val_char_3_loss: 0.0117 - val_char_3_precision_3: 0.9956 - val_char_3_recall_3: 0.9950 - val_loss: 0.0299 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 118ms/step - char_0_accuracy: 0.9991 - char_0_loss: 0.0044 - char_0_precision: 0.9991 - char_0_recall: 0.9991 - char_1_accuracy: 0.9986 - char_1_loss: 0.0080 - char_1_precision_1: 0.9986 - char_1_recall_1: 0.9980 - char_2_accuracy: 0.9967 - char_2_loss: 0.0116 - char_2_precision_2: 0.9970 - char_2_recall_2: 0.9967 - char_3_accuracy: 0.9984 - char_3_loss: 0.0075 - char_3_precision_3: 0.9989 - char_3_recall_3: 0.9978 - loss: 0.0315 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 3.2514e-04 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9969 - val_char_1_loss: 0.0093 - val_char_1_precision_1: 0.9981 - val_char_1_recall_1: 0.9962 - val_char_2_accuracy: 0.9975 - val_char_2_loss: 0.0106 - val_char_2_precision_2: 0.9975 - val_char_2_recall_2: 0.9962 - val_char_3_accuracy: 0.9962 - val_char_3_loss: 0.0077 - val_char_3_precision_3: 0.9969 - val_char_3_recall_3: 0.9962 - val_loss: 0.0279 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 117ms/step - char_0_accuracy: 0.9995 - char_0_loss: 0.0028 - char_0_precision: 1.0000 - char_0_recall: 0.9995 - char_1_accuracy: 0.9981 - char_1_loss: 0.0060 - char_1_precision_1: 0.9983 - char_1_recall_1: 0.9981 - char_2_accuracy: 0.9969 - char_2_loss: 0.0124 - char_2_precision_2: 0.9973 - char_2_recall_2: 0.9968 - char_3_accuracy: 0.9986 - char_3_loss: 0.0054 - char_3_precision_3: 0.9990 - char_3_recall_3: 0.9986 - loss: 0.0266 - val_char_0_accuracy: 0.9975 - val_char_0_loss: 0.0078 - val_char_0_precision: 0.9975 - val_char_0_recall: 0.9975 - val_char_1_accuracy: 0.9944 - val_char_1_loss: 0.0218 - val_char_1_precision_1: 0.9950 - val_char_1_recall_1: 0.9944 - val_char_2_accuracy: 0.9944 - val_char_2_loss: 0.0165 - val_char_2_precision_2: 0.9950 - val_char_2_recall_2: 0.9944 - val_char_3_accuracy: 0.9937 - val_char_3_loss: 0.0197 - val_char_3_precision_3: 0.9937 - val_char_3_recall_3: 0.9937 - val_loss: 0.0658 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 123ms/step - char_0_accuracy: 0.9991 - char_0_loss: 0.0043 - char_0_precision: 0.9991 - char_0_recall: 0.9990 - char_1_accuracy: 0.9984 - char_1_loss: 0.0067 - char_1_precision_1: 0.9990 - char_1_recall_1: 0.9980 - char_2_accuracy: 0.9978 - char_2_loss: 0.0085 - char_2_precision_2: 0.9978 - char_2_recall_2: 0.9978 - char_3_accuracy: 0.9982 - char_3_loss: 0.0064 - char_3_precision_3: 0.9986 - char_3_recall_3: 0.9978 - loss: 0.0258 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 1.4845e-04 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9981 - val_char_1_loss: 0.0049 - val_char_1_precision_1: 0.9987 - val_char_1_recall_1: 0.9981 - val_char_2_accuracy: 0.9969 - val_char_2_loss: 0.0091 - val_char_2_precision_2: 0.9969 - val_char_2_recall_2: 0.9969 - val_char_3_accuracy: 0.9981 - val_char_3_loss: 0.0074 - val_char_3_precision_3: 0.9987 - val_char_3_recall_3: 0.9981 - val_loss: 0.0216 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 123ms/step - char_0_accuracy: 0.9998 - char_0_loss: 0.0029 - char_0_precision: 0.9998 - char_0_recall: 0.9998 - char_1_accuracy: 0.9976 - char_1_loss: 0.0094 - char_1_precision_1: 0.9976 - char_1_recall_1: 0.9966 - char_2_accuracy: 0.9979 - char_2_loss: 0.0103 - char_2_precision_2: 0.9981 - char_2_recall_2: 0.9979 - char_3_accuracy: 0.9983 - char_3_loss: 0.0072 - char_3_precision_3: 0.9987 - char_3_recall_3: 0.9982 - loss: 0.0298 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 1.8260e-04 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9994 - val_char_1_loss: 0.0073 - val_char_1_precision_1: 0.9994 - val_char_1_recall_1: 0.9994 - val_char_2_accuracy: 0.9975 - val_char_2_loss: 0.0034 - val_char_2_precision_2: 0.9981 - val_char_2_recall_2: 0.9975 - val_char_3_accuracy: 0.9956 - val_char_3_loss: 0.0122 - val_char_3_precision_3: 0.9956 - val_char_3_recall_3: 0.9956 - val_loss: 0.0231 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 124ms/step - char_0_accuracy: 0.9995 - char_0_loss: 0.0038 - char_0_precision: 0.9995 - char_0_recall: 0.9992 - char_1_accuracy: 0.9972 - char_1_loss: 0.0099 - char_1_precision_1: 0.9974 - char_1_recall_1: 0.9967 - char_2_accuracy: 0.9982 - char_2_loss: 0.0058 - char_2_precision_2: 0.9983 - char_2_recall_2: 0.9982 - char_3_accuracy: 0.9985 - char_3_loss: 0.0064 - char_3_precision_3: 0.9988 - char_3_recall_3: 0.9980 - loss: 0.0259 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 0.0013 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9944 - val_char_1_loss: 0.0216 - val_char_1_precision_1: 0.9944 - val_char_1_recall_1: 0.9944 - val_char_2_accuracy: 0.9969 - val_char_2_loss: 0.0111 - val_char_2_precision_2: 0.9987 - val_char_2_recall_2: 0.9962 - val_char_3_accuracy: 0.9944 - val_char_3_loss: 0.0177 - val_char_3_precision_3: 0.9944 - val_char_3_recall_3: 0.9937 - val_loss: 0.0516 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 119ms/step - char_0_accuracy: 0.9989 - char_0_loss: 0.0037 - char_0_precision: 0.9989 - char_0_recall: 0.9989 - char_1_accuracy: 0.9987 - char_1_loss: 0.0069 - char_1_precision_1: 0.9987 - char_1_recall_1: 0.9984 - char_2_accuracy: 0.9975 - char_2_loss: 0.0080 - char_2_precision_2: 0.9975 - char_2_recall_2: 0.9972 - char_3_accuracy: 0.9983 - char_3_loss: 0.0074 - char_3_precision_3: 0.9984 - char_3_recall_3: 0.9983 - loss: 0.0260 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 3.5564e-04 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9981 - val_char_1_loss: 0.0070 - val_char_1_precision_1: 0.9981 - val_char_1_recall_1: 0.9981 - val_char_2_accuracy: 0.9969 - val_char_2_loss: 0.0079 - val_char_2_precision_2: 0.9969 - val_char_2_recall_2: 0.9969 - val_char_3_accuracy: 0.9975 - val_char_3_loss: 0.0038 - val_char_3_precision_3: 0.9975 - val_char_3_recall_3: 0.9975 - val_loss: 0.0190 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 117ms/step - char_0_accuracy: 0.9984 - char_0_loss: 0.0040 - char_0_precision: 0.9985 - char_0_recall: 0.9983 - char_1_accuracy: 0.9982 - char_1_loss: 0.0063 - char_1_precision_1: 0.9987 - char_1_recall_1: 0.9978 - char_2_accuracy: 0.9981 - char_2_loss: 0.0064 - char_2_precision_2: 0.9983 - char_2_recall_2: 0.9981 - char_3_accuracy: 0.9981 - char_3_loss: 0.0063 - char_3_precision_3: 0.9981 - char_3_recall_3: 0.9977 - loss: 0.0231 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 5.0845e-05 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9969 - val_char_1_loss: 0.0108 - val_char_1_precision_1: 0.9969 - val_char_1_recall_1: 0.9969 - val_char_2_accuracy: 0.9987 - val_char_2_loss: 0.0034 - val_char_2_precision_2: 0.9994 - val_char_2_recall_2: 0.9987 - val_char_3_accuracy: 0.9962 - val_char_3_loss: 0.0094 - val_char_3_precision_3: 0.9962 - val_char_3_recall_3: 0.9962 - val_loss: 0.0237 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 119ms/step - char_0_accuracy: 0.9976 - char_0_loss: 0.0062 - char_0_precision: 0.9978 - char_0_recall: 0.9976 - char_1_accuracy: 0.9990 - char_1_loss: 0.0052 - char_1_precision_1: 0.9992 - char_1_recall_1: 0.9990 - char_2_accuracy: 0.9985 - char_2_loss: 0.0067 - char_2_precision_2: 0.9986 - char_2_recall_2: 0.9977 - char_3_accuracy: 0.9985 - char_3_loss: 0.0070 - char_3_precision_3: 0.9986 - char_3_recall_3: 0.9985 - loss: 0.0250 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 6.4643e-05 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9987 - val_char_1_loss: 0.0094 - val_char_1_precision_1: 0.9987 - val_char_1_recall_1: 0.9981 - val_char_2_accuracy: 0.9981 - val_char_2_loss: 0.0034 - val_char_2_precision_2: 0.9981 - val_char_2_recall_2: 0.9981 - val_char_3_accuracy: 0.9956 - val_char_3_loss: 0.0124 - val_char_3_precision_3: 0.9956 - val_char_3_recall_3: 0.9956 - val_loss: 0.0253 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 118ms/step - char_0_accuracy: 0.9980 - char_0_loss: 0.0050 - char_0_precision: 0.9983 - char_0_recall: 0.9980 - char_1_accuracy: 0.9993 - char_1_loss: 0.0035 - char_1_precision_1: 0.9995 - char_1_recall_1: 0.9993 - char_2_accuracy: 0.9984 - char_2_loss: 0.0055 - char_2_precision_2: 0.9984 - char_2_recall_2: 0.9984 - char_3_accuracy: 0.9990 - char_3_loss: 0.0055 - char_3_precision_3: 0.9990 - char_3_recall_3: 0.9988 - loss: 0.0194 - val_char_0_accuracy: 0.9994 - val_char_0_loss: 0.0021 - val_char_0_precision: 1.0000 - val_char_0_recall: 0.9994 - val_char_1_accuracy: 0.9912 - val_char_1_loss: 0.0313 - val_char_1_precision_1: 0.9919 - val_char_1_recall_1: 0.9912 - val_char_2_accuracy: 0.9969 - val_char_2_loss: 0.0105 - val_char_2_precision_2: 0.9975 - val_char_2_recall_2: 0.9962 - val_char_3_accuracy: 0.9937 - val_char_3_loss: 0.0194 - val_char_3_precision_3: 0.9944 - val_char_3_recall_3: 0.9925 - val_loss: 0.0633 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 117ms/step - char_0_accuracy: 0.9992 - char_0_loss: 0.0025 - char_0_precision: 0.9992 - char_0_recall: 0.9992 - char_1_accuracy: 0.9982 - char_1_loss: 0.0057 - char_1_precision_1: 0.9982 - char_1_recall_1: 0.9980 - char_2_accuracy: 0.9996 - char_2_loss: 0.0041 - char_2_precision_2: 1.0000 - char_2_recall_2: 0.9989 - char_3_accuracy: 0.9992 - char_3_loss: 0.0034 - char_3_precision_3: 0.9993 - char_3_recall_3: 0.9991 - loss: 0.0157 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 4.1976e-04 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9975 - val_char_1_loss: 0.0164 - val_char_1_precision_1: 0.9975 - val_char_1_recall_1: 0.9975 - val_char_2_accuracy: 0.9975 - val_char_2_loss: 0.0081 - val_char_2_precision_2: 0.9981 - val_char_2_recall_2: 0.9975 - val_char_3_accuracy: 0.9962 - val_char_3_loss: 0.0112 - val_char_3_precision_3: 0.9962 - val_char_3_recall_3: 0.9962 - val_loss: 0.0360 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 121ms/step - char_0_accuracy: 0.9988 - char_0_loss: 0.0044 - char_0_precision: 0.9988 - char_0_recall: 0.9988 - char_1_accuracy: 0.9985 - char_1_loss: 0.0056 - char_1_precision_1: 0.9988 - char_1_recall_1: 0.9985 - char_2_accuracy: 0.9983 - char_2_loss: 0.0055 - char_2_precision_2: 0.9983 - char_2_recall_2: 0.9976 - char_3_accuracy: 0.9990 - char_3_loss: 0.0036 - char_3_precision_3: 0.9990 - char_3_recall_3: 0.9990 - loss: 0.0189 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 6.4114e-05 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9981 - val_char_1_loss: 0.0062 - val_char_1_precision_1: 0.9981 - val_char_1_recall_1: 0.9981 - val_char_2_accuracy: 0.9994 - val_char_2_loss: 0.0018 - val_char_2_precision_2: 1.0000 - val_char_2_recall_2: 0.9994 - val_char_3_accuracy: 0.9975 - val_char_3_loss: 0.0045 - val_char_3_precision_3: 0.9975 - val_char_3_recall_3: 0.9975 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 126ms/step - char_0_accuracy: 0.9995 - char_0_loss: 0.0033 - char_0_precision: 0.9995 - char_0_recall: 0.9995 - char_1_accuracy: 0.9996 - char_1_loss: 0.0037 - char_1_precision_1: 0.9996 - char_1_recall_1: 0.9991 - char_2_accuracy: 0.9983 - char_2_loss: 0.0051 - char_2_precision_2: 0.9984 - char_2_recall_2: 0.9983 - char_3_accuracy: 0.9986 - char_3_loss: 0.0051 - char_3_precision_3: 0.9990 - char_3_recall_3: 0.9984 - loss: 0.0172 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 6.2342e-05 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9975 - val_char_1_loss: 0.0151 - val_char_1_precision_1: 0.9975 - val_char_1_recall_1: 0.9975 - val_char_2_accuracy: 1.0000 - val_char_2_loss: 0.0011 - val_char_2_precision_2: 1.0000 - val_char_2_recall_2: 1.0000 - val_char_3_accuracy: 0.9969 - val_char_3_loss: 0.0084 - val_char_3_precision_3: 0.9975 - val_char_3_recall_3: 0.9969 - val_loss: 0.0247 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 114ms/step - char_0_accuracy: 0.9998 - char_0_loss: 0.0014 - char_0_precision: 0.9998 - char_0_recall: 0.9997 - char_1_accuracy: 0.9986 - char_1_loss: 0.0039 - char_1_precision_1: 0.9986 - char_1_recall_1: 0.9985 - char_2_accuracy: 0.9992 - char_2_loss: 0.0032 - char_2_precision_2: 0.9992 - char_2_recall_2: 0.9990 - char_3_accuracy: 1.0000 - char_3_loss: 0.0019 - char_3_precision_3: 1.0000 - char_3_recall_3: 1.0000 - loss: 0.0105 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 2.1684e-04 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9962 - val_char_1_loss: 0.0181 - val_char_1_precision_1: 0.9962 - val_char_1_recall_1: 0.9962 - val_char_2_accuracy: 0.9994 - val_char_2_loss: 0.0047 - val_char_2_precision_2: 1.0000 - val_char_2_recall_2: 0.9994 - val_char_3_accuracy: 0.9969 - val_char_3_loss: 0.0090 - val_char_3_precision_3: 0.9975 - val_char_3_recall_3: 0.9969 - val_loss: 0.0321 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 111ms/step - char_0_accuracy: 0.9997 - char_0_loss: 0.0015 - char_0_precision: 0.9997 - char_0_recall: 0.9997 - char_1_accuracy: 0.9976 - char_1_loss: 0.0058 - char_1_precision_1: 0.9977 - char_1_recall_1: 0.9975 - char_2_accuracy: 0.9995 - char_2_loss: 0.0035 - char_2_precision_2: 0.9995 - char_2_recall_2: 0.9995 - char_3_accuracy: 0.9982 - char_3_loss: 0.0058 - char_3_precision_3: 0.9982 - char_3_recall_3: 0.9982 - loss: 0.0166 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 9.0437e-05 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9975 - val_char_1_loss: 0.0100 - val_char_1_precision_1: 0.9975 - val_char_1_recall_1: 0.9975 - val_char_2_accuracy: 0.9994 - val_char_2_loss: 0.0012 - val_char_2_precision_2: 0.9994 - val_char_2_recall_2: 0.9994 - val_char_3_accuracy: 0.9987 - val_char_3_loss: 0.0065 - val_char_3_precision_3: 0.9987 - val_char_3_recall_3: 0.9987 - val_loss: 0.0179 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 114ms/step - char_0_accuracy: 0.9997 - char_0_loss: 0.0020 - char_0_precision: 0.9998 - char_0_recall: 0.9997 - char_1_accuracy: 0.9988 - char_1_loss: 0.0048 - char_1_precision_1: 0.9989 - char_1_recall_1: 0.9988 - char_2_accuracy: 0.9977 - char_2_loss: 0.0061 - char_2_precision_2: 0.9979 - char_2_recall_2: 0.9977 - char_3_accuracy: 0.9990 - char_3_loss: 0.0040 - char_3_precision_3: 0.9990 - char_3_recall_3: 0.9990 - loss: 0.0169 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 2.8997e-05 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9987 - val_char_1_loss: 0.0049 - val_char_1_precision_1: 0.9987 - val_char_1_recall_1: 0.9987 - val_char_2_accuracy: 0.9969 - val_char_2_loss: 0.0097 - val_char_2_precision_2: 0.9969 - val_char_2_recall_2: 0.9969 - val_char_3_accuracy: 0.9987 - val_char_3_loss: 0.0039 - val_char_3_precision_3: 0.9987 - val_char_3_recall_3: 0.9987 - val_loss: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - char_0_accuracy: 0.9999 - char_0_loss: 0.0010 - char_0_precision: 0.9999 - char_0_recall: 0.9999 - char_1_accuracy: 0.9997 - char_1_loss: 0.0028 - char_1_precision_1: 0.9997 - char_1_recall_1: 0.9996 - char_2_accuracy: 0.9992 - char_2_loss: 0.0038 - char_2_precision_2: 0.9994 - char_2_recall_2: 0.9991 - char_3_accuracy: 0.9989 - char_3_loss: 0.0037 - char_3_precision_3: 0.9989 - char_3_recall_3: 0.9985 - loss: 0.0112\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 113ms/step - char_0_accuracy: 0.9999 - char_0_loss: 0.0010 - char_0_precision: 0.9999 - char_0_recall: 0.9999 - char_1_accuracy: 0.9997 - char_1_loss: 0.0028 - char_1_precision_1: 0.9997 - char_1_recall_1: 0.9996 - char_2_accuracy: 0.9992 - char_2_loss: 0.0038 - char_2_precision_2: 0.9994 - char_2_recall_2: 0.9991 - char_3_accuracy: 0.9989 - char_3_loss: 0.0037 - char_3_precision_3: 0.9989 - char_3_recall_3: 0.9985 - loss: 0.0112 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 3.4860e-05 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9975 - val_char_1_loss: 0.0085 - val_char_1_precision_1: 0.9981 - val_char_1_recall_1: 0.9975 - val_char_2_accuracy: 1.0000 - val_char_2_loss: 0.0012 - val_char_2_precision_2: 1.0000 - val_char_2_recall_2: 1.0000 - val_char_3_accuracy: 0.9962 - val_char_3_loss: 0.0110 - val_char_3_precision_3: 0.9962 - val_char_3_recall_3: 0.9956 - val_loss: 0.0208 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 113ms/step - char_0_accuracy: 0.9996 - char_0_loss: 0.0014 - char_0_precision: 0.9996 - char_0_recall: 0.9996 - char_1_accuracy: 0.9996 - char_1_loss: 0.0020 - char_1_precision_1: 0.9996 - char_1_recall_1: 0.9996 - char_2_accuracy: 0.9996 - char_2_loss: 0.0030 - char_2_precision_2: 0.9996 - char_2_recall_2: 0.9993 - char_3_accuracy: 0.9981 - char_3_loss: 0.0062 - char_3_precision_3: 0.9983 - char_3_recall_3: 0.9979 - loss: 0.0126 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 4.2545e-05 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9987 - val_char_1_loss: 0.0057 - val_char_1_precision_1: 0.9987 - val_char_1_recall_1: 0.9987 - val_char_2_accuracy: 0.9994 - val_char_2_loss: 0.0011 - val_char_2_precision_2: 0.9994 - val_char_2_recall_2: 0.9994 - val_char_3_accuracy: 0.9981 - val_char_3_loss: 0.0053 - val_char_3_precision_3: 0.9981 - val_char_3_recall_3: 0.9981 - val_loss: 0.0122 - learning_rate: 2.0000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 111ms/step - char_0_accuracy: 0.9997 - char_0_loss: 0.0016 - char_0_precision: 0.9997 - char_0_recall: 0.9997 - char_1_accuracy: 0.9983 - char_1_loss: 0.0036 - char_1_precision_1: 0.9983 - char_1_recall_1: 0.9981 - char_2_accuracy: 0.9996 - char_2_loss: 0.0027 - char_2_precision_2: 0.9997 - char_2_recall_2: 0.9996 - char_3_accuracy: 0.9988 - char_3_loss: 0.0036 - char_3_precision_3: 0.9990 - char_3_recall_3: 0.9988 - loss: 0.0115 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 2.7617e-05 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9987 - val_char_1_loss: 0.0056 - val_char_1_precision_1: 0.9987 - val_char_1_recall_1: 0.9987 - val_char_2_accuracy: 0.9994 - val_char_2_loss: 0.0015 - val_char_2_precision_2: 0.9994 - val_char_2_recall_2: 0.9994 - val_char_3_accuracy: 0.9987 - val_char_3_loss: 0.0043 - val_char_3_precision_3: 0.9987 - val_char_3_recall_3: 0.9987 - val_loss: 0.0114 - learning_rate: 2.0000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 113ms/step - char_0_accuracy: 0.9991 - char_0_loss: 0.0017 - char_0_precision: 0.9991 - char_0_recall: 0.9991 - char_1_accuracy: 0.9995 - char_1_loss: 0.0026 - char_1_precision_1: 0.9995 - char_1_recall_1: 0.9995 - char_2_accuracy: 0.9995 - char_2_loss: 0.0036 - char_2_precision_2: 0.9995 - char_2_recall_2: 0.9994 - char_3_accuracy: 0.9995 - char_3_loss: 0.0024 - char_3_precision_3: 0.9996 - char_3_recall_3: 0.9995 - loss: 0.0104 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 2.5301e-05 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9987 - val_char_1_loss: 0.0057 - val_char_1_precision_1: 0.9987 - val_char_1_recall_1: 0.9987 - val_char_2_accuracy: 0.9994 - val_char_2_loss: 0.0012 - val_char_2_precision_2: 0.9994 - val_char_2_recall_2: 0.9994 - val_char_3_accuracy: 0.9987 - val_char_3_loss: 0.0056 - val_char_3_precision_3: 0.9987 - val_char_3_recall_3: 0.9981 - val_loss: 0.0125 - learning_rate: 2.0000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 113ms/step - char_0_accuracy: 0.9995 - char_0_loss: 0.0015 - char_0_precision: 0.9995 - char_0_recall: 0.9995 - char_1_accuracy: 0.9999 - char_1_loss: 0.0015 - char_1_precision_1: 0.9999 - char_1_recall_1: 0.9996 - char_2_accuracy: 0.9993 - char_2_loss: 0.0030 - char_2_precision_2: 0.9993 - char_2_recall_2: 0.9991 - char_3_accuracy: 1.0000 - char_3_loss: 0.0015 - char_3_precision_3: 1.0000 - char_3_recall_3: 1.0000 - loss: 0.0076 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 1.9146e-05 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9994 - val_char_1_loss: 0.0051 - val_char_1_precision_1: 0.9994 - val_char_1_recall_1: 0.9994 - val_char_2_accuracy: 1.0000 - val_char_2_loss: 6.2274e-04 - val_char_2_precision_2: 1.0000 - val_char_2_recall_2: 1.0000 - val_char_3_accuracy: 0.9987 - val_char_3_loss: 0.0047 - val_char_3_precision_3: 0.9987 - val_char_3_recall_3: 0.9987 - val_loss: 0.0104 - learning_rate: 2.0000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 114ms/step - char_0_accuracy: 0.9995 - char_0_loss: 0.0028 - char_0_precision: 0.9995 - char_0_recall: 0.9995 - char_1_accuracy: 1.0000 - char_1_loss: 0.0014 - char_1_precision_1: 1.0000 - char_1_recall_1: 0.9998 - char_2_accuracy: 0.9992 - char_2_loss: 0.0030 - char_2_precision_2: 0.9992 - char_2_recall_2: 0.9992 - char_3_accuracy: 0.9992 - char_3_loss: 0.0019 - char_3_precision_3: 0.9992 - char_3_recall_3: 0.9992 - loss: 0.0091 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 4.3474e-05 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9994 - val_char_1_loss: 0.0058 - val_char_1_precision_1: 0.9994 - val_char_1_recall_1: 0.9994 - val_char_2_accuracy: 1.0000 - val_char_2_loss: 8.4953e-04 - val_char_2_precision_2: 1.0000 - val_char_2_recall_2: 1.0000 - val_char_3_accuracy: 0.9981 - val_char_3_loss: 0.0050 - val_char_3_precision_3: 0.9981 - val_char_3_recall_3: 0.9981 - val_loss: 0.0117 - learning_rate: 2.0000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 115ms/step - char_0_accuracy: 0.9999 - char_0_loss: 8.0947e-04 - char_0_precision: 0.9999 - char_0_recall: 0.9998 - char_1_accuracy: 0.9995 - char_1_loss: 0.0028 - char_1_precision_1: 0.9995 - char_1_recall_1: 0.9994 - char_2_accuracy: 0.9991 - char_2_loss: 0.0029 - char_2_precision_2: 0.9991 - char_2_recall_2: 0.9991 - char_3_accuracy: 0.9999 - char_3_loss: 0.0021 - char_3_precision_3: 0.9999 - char_3_recall_3: 0.9997 - loss: 0.0087 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 3.2173e-05 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9987 - val_char_1_loss: 0.0058 - val_char_1_precision_1: 0.9987 - val_char_1_recall_1: 0.9987 - val_char_2_accuracy: 1.0000 - val_char_2_loss: 7.3249e-04 - val_char_2_precision_2: 1.0000 - val_char_2_recall_2: 1.0000 - val_char_3_accuracy: 0.9981 - val_char_3_loss: 0.0062 - val_char_3_precision_3: 0.9981 - val_char_3_recall_3: 0.9981 - val_loss: 0.0127 - learning_rate: 2.0000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 112ms/step - char_0_accuracy: 0.9999 - char_0_loss: 0.0010 - char_0_precision: 0.9999 - char_0_recall: 0.9999 - char_1_accuracy: 0.9997 - char_1_loss: 0.0017 - char_1_precision_1: 0.9998 - char_1_recall_1: 0.9997 - char_2_accuracy: 0.9999 - char_2_loss: 0.0013 - char_2_precision_2: 0.9999 - char_2_recall_2: 0.9996 - char_3_accuracy: 0.9999 - char_3_loss: 0.0017 - char_3_precision_3: 0.9999 - char_3_recall_3: 0.9999 - loss: 0.0058 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 1.6541e-05 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9994 - val_char_1_loss: 0.0057 - val_char_1_precision_1: 0.9994 - val_char_1_recall_1: 0.9994 - val_char_2_accuracy: 1.0000 - val_char_2_loss: 8.7034e-04 - val_char_2_precision_2: 1.0000 - val_char_2_recall_2: 1.0000 - val_char_3_accuracy: 0.9975 - val_char_3_loss: 0.0068 - val_char_3_precision_3: 0.9975 - val_char_3_recall_3: 0.9975 - val_loss: 0.0134 - learning_rate: 2.0000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - char_0_accuracy: 1.0000 - char_0_loss: 0.0010 - char_0_precision: 1.0000 - char_0_recall: 1.0000 - char_1_accuracy: 0.9994 - char_1_loss: 0.0023 - char_1_precision_1: 0.9999 - char_1_recall_1: 0.9994 - char_2_accuracy: 0.9992 - char_2_loss: 0.0024 - char_2_precision_2: 0.9992 - char_2_recall_2: 0.9992 - char_3_accuracy: 0.9998 - char_3_loss: 0.0017 - char_3_precision_3: 0.9998 - char_3_recall_3: 0.9994 - loss: 0.0074 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 1.6783e-05 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9994 - val_char_1_loss: 0.0058 - val_char_1_precision_1: 0.9994 - val_char_1_recall_1: 0.9994 - val_char_2_accuracy: 1.0000 - val_char_2_loss: 8.1932e-04 - val_char_2_precision_2: 1.0000 - val_char_2_recall_2: 1.0000 - val_char_3_accuracy: 0.9975 - val_char_3_loss: 0.0072 - val_char_3_precision_3: 0.9981 - val_char_3_recall_3: 0.9975 - val_loss: 0.0139 - learning_rate: 2.0000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - char_0_accuracy: 1.0000 - char_0_loss: 9.5130e-04 - char_0_precision: 1.0000 - char_0_recall: 1.0000 - char_1_accuracy: 0.9998 - char_1_loss: 0.0014 - char_1_precision_1: 0.9998 - char_1_recall_1: 0.9998 - char_2_accuracy: 0.9998 - char_2_loss: 0.0012 - char_2_precision_2: 0.9998 - char_2_recall_2: 0.9998 - char_3_accuracy: 0.9999 - char_3_loss: 9.9508e-04 - char_3_precision_3: 0.9999 - char_3_recall_3: 0.9999 - loss: 0.0045\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 113ms/step - char_0_accuracy: 1.0000 - char_0_loss: 9.5163e-04 - char_0_precision: 1.0000 - char_0_recall: 1.0000 - char_1_accuracy: 0.9998 - char_1_loss: 0.0014 - char_1_precision_1: 0.9998 - char_1_recall_1: 0.9998 - char_2_accuracy: 0.9998 - char_2_loss: 0.0012 - char_2_precision_2: 0.9998 - char_2_recall_2: 0.9998 - char_3_accuracy: 0.9999 - char_3_loss: 9.9692e-04 - char_3_precision_3: 0.9999 - char_3_recall_3: 0.9999 - loss: 0.0045 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 1.3328e-05 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9994 - val_char_1_loss: 0.0053 - val_char_1_precision_1: 0.9994 - val_char_1_recall_1: 0.9994 - val_char_2_accuracy: 1.0000 - val_char_2_loss: 7.6608e-04 - val_char_2_precision_2: 1.0000 - val_char_2_recall_2: 1.0000 - val_char_3_accuracy: 0.9981 - val_char_3_loss: 0.0066 - val_char_3_precision_3: 0.9981 - val_char_3_recall_3: 0.9975 - val_loss: 0.0127 - learning_rate: 2.0000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 111ms/step - char_0_accuracy: 0.9998 - char_0_loss: 7.5678e-04 - char_0_precision: 0.9998 - char_0_recall: 0.9998 - char_1_accuracy: 0.9991 - char_1_loss: 0.0020 - char_1_precision_1: 0.9999 - char_1_recall_1: 0.9991 - char_2_accuracy: 0.9996 - char_2_loss: 0.0018 - char_2_precision_2: 0.9996 - char_2_recall_2: 0.9995 - char_3_accuracy: 0.9995 - char_3_loss: 0.0019 - char_3_precision_3: 0.9995 - char_3_recall_3: 0.9995 - loss: 0.0065 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 1.5776e-05 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9987 - val_char_1_loss: 0.0055 - val_char_1_precision_1: 0.9987 - val_char_1_recall_1: 0.9987 - val_char_2_accuracy: 1.0000 - val_char_2_loss: 6.9284e-04 - val_char_2_precision_2: 1.0000 - val_char_2_recall_2: 1.0000 - val_char_3_accuracy: 0.9981 - val_char_3_loss: 0.0061 - val_char_3_precision_3: 0.9981 - val_char_3_recall_3: 0.9975 - val_loss: 0.0123 - learning_rate: 4.0000e-05\n",
      "Epoch 50/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 111ms/step - char_0_accuracy: 1.0000 - char_0_loss: 6.9266e-04 - char_0_precision: 1.0000 - char_0_recall: 1.0000 - char_1_accuracy: 0.9998 - char_1_loss: 0.0019 - char_1_precision_1: 0.9998 - char_1_recall_1: 0.9998 - char_2_accuracy: 0.9998 - char_2_loss: 0.0013 - char_2_precision_2: 0.9998 - char_2_recall_2: 0.9998 - char_3_accuracy: 0.9997 - char_3_loss: 0.0012 - char_3_precision_3: 0.9997 - char_3_recall_3: 0.9997 - loss: 0.0051 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 1.5220e-05 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9994 - val_char_1_loss: 0.0053 - val_char_1_precision_1: 0.9994 - val_char_1_recall_1: 0.9994 - val_char_2_accuracy: 1.0000 - val_char_2_loss: 6.3296e-04 - val_char_2_precision_2: 1.0000 - val_char_2_recall_2: 1.0000 - val_char_3_accuracy: 0.9981 - val_char_3_loss: 0.0060 - val_char_3_precision_3: 0.9981 - val_char_3_recall_3: 0.9975 - val_loss: 0.0119 - learning_rate: 4.0000e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 111ms/step - char_0_accuracy: 0.9995 - char_0_loss: 0.0012 - char_0_precision: 0.9997 - char_0_recall: 0.9993 - char_1_accuracy: 0.9994 - char_1_loss: 0.0021 - char_1_precision_1: 0.9997 - char_1_recall_1: 0.9988 - char_2_accuracy: 0.9999 - char_2_loss: 0.0012 - char_2_precision_2: 0.9999 - char_2_recall_2: 0.9999 - char_3_accuracy: 0.9999 - char_3_loss: 0.0015 - char_3_precision_3: 0.9999 - char_3_recall_3: 0.9999 - loss: 0.0060 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 1.4690e-05 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9994 - val_char_1_loss: 0.0052 - val_char_1_precision_1: 0.9994 - val_char_1_recall_1: 0.9994 - val_char_2_accuracy: 1.0000 - val_char_2_loss: 6.6668e-04 - val_char_2_precision_2: 1.0000 - val_char_2_recall_2: 1.0000 - val_char_3_accuracy: 0.9981 - val_char_3_loss: 0.0061 - val_char_3_precision_3: 0.9981 - val_char_3_recall_3: 0.9975 - val_loss: 0.0120 - learning_rate: 4.0000e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 114ms/step - char_0_accuracy: 0.9999 - char_0_loss: 6.1546e-04 - char_0_precision: 0.9999 - char_0_recall: 0.9999 - char_1_accuracy: 0.9993 - char_1_loss: 0.0023 - char_1_precision_1: 0.9994 - char_1_recall_1: 0.9993 - char_2_accuracy: 1.0000 - char_2_loss: 0.0011 - char_2_precision_2: 1.0000 - char_2_recall_2: 1.0000 - char_3_accuracy: 0.9999 - char_3_loss: 0.0011 - char_3_precision_3: 0.9999 - char_3_recall_3: 0.9999 - loss: 0.0052 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 1.5657e-05 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9994 - val_char_1_loss: 0.0052 - val_char_1_precision_1: 0.9994 - val_char_1_recall_1: 0.9994 - val_char_2_accuracy: 1.0000 - val_char_2_loss: 6.3862e-04 - val_char_2_precision_2: 1.0000 - val_char_2_recall_2: 1.0000 - val_char_3_accuracy: 0.9981 - val_char_3_loss: 0.0059 - val_char_3_precision_3: 0.9981 - val_char_3_recall_3: 0.9975 - val_loss: 0.0117 - learning_rate: 4.0000e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - char_0_accuracy: 1.0000 - char_0_loss: 8.9508e-04 - char_0_precision: 1.0000 - char_0_recall: 1.0000 - char_1_accuracy: 0.9992 - char_1_loss: 0.0026 - char_1_precision_1: 0.9992 - char_1_recall_1: 0.9992 - char_2_accuracy: 0.9996 - char_2_loss: 0.0018 - char_2_precision_2: 0.9996 - char_2_recall_2: 0.9996 - char_3_accuracy: 1.0000 - char_3_loss: 0.0016 - char_3_precision_3: 1.0000 - char_3_recall_3: 0.9994 - loss: 0.0069\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 115ms/step - char_0_accuracy: 1.0000 - char_0_loss: 8.9342e-04 - char_0_precision: 1.0000 - char_0_recall: 1.0000 - char_1_accuracy: 0.9992 - char_1_loss: 0.0026 - char_1_precision_1: 0.9992 - char_1_recall_1: 0.9992 - char_2_accuracy: 0.9996 - char_2_loss: 0.0018 - char_2_precision_2: 0.9996 - char_2_recall_2: 0.9996 - char_3_accuracy: 1.0000 - char_3_loss: 0.0016 - char_3_precision_3: 1.0000 - char_3_recall_3: 0.9994 - loss: 0.0069 - val_char_0_accuracy: 1.0000 - val_char_0_loss: 1.6577e-05 - val_char_0_precision: 1.0000 - val_char_0_recall: 1.0000 - val_char_1_accuracy: 0.9987 - val_char_1_loss: 0.0055 - val_char_1_precision_1: 0.9994 - val_char_1_recall_1: 0.9987 - val_char_2_accuracy: 1.0000 - val_char_2_loss: 6.7206e-04 - val_char_2_precision_2: 1.0000 - val_char_2_recall_2: 1.0000 - val_char_3_accuracy: 0.9981 - val_char_3_loss: 0.0059 - val_char_3_precision_3: 0.9981 - val_char_3_recall_3: 0.9975 - val_loss: 0.0121 - learning_rate: 4.0000e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating final model accuracy...\n",
      "Processed 100/1600 samples...\n",
      "Processed 200/1600 samples...\n",
      "Processed 300/1600 samples...\n",
      "Processed 400/1600 samples...\n",
      "Processed 500/1600 samples...\n",
      "Processed 600/1600 samples...\n",
      "Processed 700/1600 samples...\n",
      "Processed 800/1600 samples...\n",
      "Processed 900/1600 samples...\n",
      "Processed 1000/1600 samples...\n",
      "Processed 1100/1600 samples...\n",
      "Processed 1200/1600 samples...\n",
      "Processed 1300/1600 samples...\n",
      "Processed 1400/1600 samples...\n",
      "Processed 1500/1600 samples...\n",
      "Processed 1600/1600 samples...\n",
      "\n",
      "Final Model Performance:\n",
      "Character-level accuracy: 99.95%\n",
      "Full-text accuracy: 99.81%\n",
      "\n",
      "Model saved as: models/captcha_model_char0.9995_text0.9981.keras\n",
      "\n",
      "Testing on random validation samples:\n",
      "True: FNPL, Predicted: FNPL ✓\n",
      "True: 7PNL, Predicted: 7PNL ✓\n",
      "True: 3YW9, Predicted: 3YW9 ✓\n",
      "True: AXYR, Predicted: AXYR ✓\n",
      "True: HT5P, Predicted: HT5P ✓\n",
      "True: 9L8L, Predicted: 9L8L ✓\n",
      "True: 4ZAY, Predicted: 4ZAY ✓\n",
      "True: 7F5H, Predicted: 7F5H ✓\n",
      "True: CAW9, Predicted: CAW9 ✓\n",
      "True: 4FEU, Predicted: 4FEU ✓\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Constants\n",
    "HARDCODED_CHAR_SET = ['2', '3', '4', '5', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', \n",
    "                      'H', 'K', 'L', 'M', 'N', 'P', 'R', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "\n",
    "IMAGE_HEIGHT = 25\n",
    "IMAGE_WIDTH = 65\n",
    "NUM_CHANNELS = 1\n",
    "NUM_CHARS = 4\n",
    "CHAR_SET_LEN = len(HARDCODED_CHAR_SET)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "def load_dataset(data_dir):\n",
    "    \"\"\"Load dataset from directory where filenames contain labels\"\"\"\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for filename in os.listdir(data_dir):\n",
    "        if filename.endswith('.png'):\n",
    "            # Extract label from filename (first 4 characters, excluding any dots)\n",
    "            label = filename.split('.')[0][:4]  # This gets first 4 chars before the dot\n",
    "            \n",
    "            # Verify all characters are in our character set and label length is correct\n",
    "            if len(label) == NUM_CHARS and all(c in HARDCODED_CHAR_SET for c in label):\n",
    "                image_paths.append(os.path.join(data_dir, filename))\n",
    "                labels.append(label)\n",
    "            else:\n",
    "                print(f\"Skipping {filename} - invalid label format\")\n",
    "    \n",
    "    if not image_paths:\n",
    "        raise ValueError(\"No valid images found in directory\")\n",
    "        \n",
    "    print(f\"Found {len(image_paths)} valid images\")\n",
    "    return image_paths, labels\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"Preprocess a single image\"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path).convert('L')  # Convert to grayscale\n",
    "        img = img.resize((IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "        img_array = np.array(img) / 255.0  # Normalize to [0,1]\n",
    "        img_array = np.expand_dims(img_array, axis=-1)  # Add channel dimension\n",
    "        return img_array\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def augment_image(img_array):\n",
    "    \"\"\"Apply random augmentations to the image\"\"\"\n",
    "    # Random brightness\n",
    "    delta = np.random.uniform(-0.1, 0.1)\n",
    "    img_array = img_array + delta\n",
    "    img_array = np.clip(img_array, 0, 1)\n",
    "    \n",
    "    # Random contrast\n",
    "    factor = np.random.uniform(0.8, 1.2)\n",
    "    img_array = (img_array - 0.5) * factor + 0.5\n",
    "    img_array = np.clip(img_array, 0, 1)\n",
    "    \n",
    "    return img_array\n",
    "\n",
    "class CaptchaDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, image_paths, labels, batch_size=32, augment=True):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.indices = list(range(len(self.image_paths)))\n",
    "        self.augment = augment\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_paths = [self.image_paths[i] for i in batch_indices]\n",
    "        batch_labels = [self.labels[i] for i in batch_indices]\n",
    "        \n",
    "        # Initialize input array\n",
    "        X = np.zeros((self.batch_size, IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS))\n",
    "        \n",
    "        # Initialize output arrays - one for each character\n",
    "        y = {f'char_{i}': np.zeros((self.batch_size, CHAR_SET_LEN)) for i in range(NUM_CHARS)}\n",
    "        \n",
    "        for i, (path, label) in enumerate(zip(batch_paths, batch_labels)):\n",
    "            img_array = preprocess_image(path)\n",
    "            if img_array is not None:\n",
    "                # Apply augmentation if enabled\n",
    "                if self.augment:\n",
    "                    img_array = augment_image(img_array)\n",
    "                X[i] = img_array\n",
    "                \n",
    "                # One-hot encode each character\n",
    "                for j, char in enumerate(label):\n",
    "                    char_idx = HARDCODED_CHAR_SET.index(char)\n",
    "                    y[f'char_{j}'][i, char_idx] = 1\n",
    "        \n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Shuffle indices after each epoch\"\"\"\n",
    "        random.shuffle(self.indices)\n",
    "\n",
    "def create_model():\n",
    "    \"\"\"Create an improved CNN model with residual connections and deeper architecture\"\"\"\n",
    "    inputs = layers.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS))\n",
    "    \n",
    "    # Initial convolution\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # First residual block\n",
    "    skip = x\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Add()([x, skip])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.SpatialDropout2D(0.1)(x)\n",
    "    \n",
    "    # Second residual block\n",
    "    skip = layers.Conv2D(64, (1, 1), padding='same')(x)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Add()([x, skip])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.SpatialDropout2D(0.1)(x)\n",
    "    \n",
    "    # Third residual block\n",
    "    skip = layers.Conv2D(128, (1, 1), padding='same')(x)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Add()([x, skip])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.SpatialDropout2D(0.1)(x)\n",
    "    \n",
    "    # Dense layers with increased capacity\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(1024, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Output layers with named outputs\n",
    "    outputs = {}\n",
    "    for i in range(NUM_CHARS):\n",
    "        outputs[f'char_{i}'] = layers.Dense(CHAR_SET_LEN, activation='softmax', name=f'char_{i}')(x)\n",
    "    \n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # Enhanced optimizer configuration\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate=0.001,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "        epsilon=1e-07,\n",
    "        amsgrad=True,\n",
    "        clipnorm=1.0,\n",
    "        weight_decay=1e-6  # L2 regularization\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss={f'char_{i}': 'categorical_crossentropy' for i in range(NUM_CHARS)},\n",
    "        metrics={f'char_{i}': ['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()] \n",
    "                for i in range(NUM_CHARS)}\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def decode_prediction(prediction):\n",
    "    \"\"\"Convert model output to text\"\"\"\n",
    "    text = ''\n",
    "    for i in range(NUM_CHARS):\n",
    "        char_pred = prediction[f'char_{i}']\n",
    "        char_idx = np.argmax(char_pred[0])\n",
    "        text += HARDCODED_CHAR_SET[char_idx]\n",
    "    return text\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training history\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot loss\n",
    "    ax1.plot(history.history['loss'], label='Training Loss')\n",
    "    ax1.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax1.set_title('Model Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Plot accuracy (average of all characters)\n",
    "    accuracy_metrics = [key for key in history.history.keys() if 'accuracy' in key and 'val' not in key]\n",
    "    val_accuracy_metrics = [key for key in history.history.keys() if 'accuracy' in key and 'val' in key]\n",
    "    \n",
    "    train_acc = np.mean([history.history[metric] for metric in accuracy_metrics], axis=0)\n",
    "    val_acc = np.mean([history.history[metric] for metric in val_accuracy_metrics], axis=0)\n",
    "    \n",
    "    ax2.plot(train_acc, label='Training Accuracy')\n",
    "    ax2.plot(val_acc, label='Validation Accuracy')\n",
    "    ax2.set_title('Model Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    # Set your data directory\n",
    "    data_dir = 'captcha_images_8k'  # Replace with your image directory path\n",
    "    \n",
    "    # Create necessary directories\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    os.makedirs('logs', exist_ok=True)\n",
    "    \n",
    "    # Load dataset\n",
    "    print(\"Loading dataset...\")\n",
    "    image_paths, labels = load_dataset(data_dir)\n",
    "    print(f\"Total images found: {len(image_paths)}\")\n",
    "    \n",
    "    # Split dataset\n",
    "    train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "        image_paths, labels, test_size=0.2, random_state=42\n",
    "    )\n",
    "    print(f\"Training samples: {len(train_paths)}\")\n",
    "    print(f\"Validation samples: {len(val_paths)}\")\n",
    "    \n",
    "    # Create data generators\n",
    "    train_generator = CaptchaDataGenerator(train_paths, train_labels, BATCH_SIZE, augment=True)\n",
    "    val_generator = CaptchaDataGenerator(val_paths, val_labels, BATCH_SIZE, augment=False)\n",
    "    \n",
    "    # Calculate steps per epoch\n",
    "    steps_per_epoch = len(train_paths) // BATCH_SIZE\n",
    "    validation_steps = len(val_paths) // BATCH_SIZE\n",
    "    \n",
    "    # Create and compile model\n",
    "    print(\"Creating model...\")\n",
    "    model = create_model()\n",
    "    model.summary()\n",
    "    \n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath='models/captcha_model_val_loss_{val_loss:.4f}.keras',\n",
    "            save_best_only=True,\n",
    "            monitor='val_loss'\n",
    "        ),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "            monitor='val_loss',\n",
    "            min_delta=1e-4\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            factor=0.2,\n",
    "            patience=5,\n",
    "            min_lr=1e-6,\n",
    "            monitor='val_loss',\n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.CSVLogger('training_log.csv'),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "    ]\n",
    "    \n",
    "    # Train model\n",
    "    print(\"Training model...\")\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs=100,  # Increased epochs\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_steps=validation_steps,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    plot_training_history(history)\n",
    "    \n",
    "    # Evaluate final model accuracy\n",
    "    print(\"\\nEvaluating final model accuracy...\")\n",
    "    total_correct_chars = 0\n",
    "    total_correct_texts = 0\n",
    "    total_samples = len(val_paths)\n",
    "\n",
    "    for i, (img_path, true_label) in enumerate(zip(val_paths, val_labels)):\n",
    "        img = preprocess_image(img_path)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        pred = model.predict(img, verbose=0)\n",
    "        pred_text = decode_prediction(pred)\n",
    "        \n",
    "        # Count correct characters\n",
    "        for true_char, pred_char in zip(true_label, pred_text):\n",
    "            if true_char == pred_char:\n",
    "                total_correct_chars += 1\n",
    "        \n",
    "        # Count completely correct texts\n",
    "        if true_label == pred_text:\n",
    "            total_correct_texts += 1\n",
    "        \n",
    "        # Print progress every 100 samples\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Processed {i + 1}/{total_samples} samples...\")\n",
    "\n",
    "    # Calculate final accuracies\n",
    "    char_accuracy = total_correct_chars / (total_samples * NUM_CHARS)\n",
    "    text_accuracy = total_correct_texts / total_samples\n",
    "\n",
    "    print(\"\\nFinal Model Performance:\")\n",
    "    print(f\"Character-level accuracy: {char_accuracy:.2%}\")\n",
    "    print(f\"Full-text accuracy: {text_accuracy:.2%}\")\n",
    "    \n",
    "    # Save final model with accuracies in filename\n",
    "    final_model_name = f'captcha_model_char{char_accuracy:.4f}_text{text_accuracy:.4f}.keras'\n",
    "    final_model_path = os.path.join('models', final_model_name)\n",
    "    model.save(final_model_path)\n",
    "    print(f\"\\nModel saved as: {final_model_path}\")\n",
    "    \n",
    "    # Test on some validation samples\n",
    "    print(\"\\nTesting on random validation samples:\")\n",
    "    for i in range(10):\n",
    "        idx = random.randint(0, len(val_paths) - 1)\n",
    "        img_path = val_paths[idx]\n",
    "        true_label = val_labels[idx]\n",
    "        \n",
    "        # Make prediction\n",
    "        img = preprocess_image(img_path)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        pred = model.predict(img, verbose=0)\n",
    "        pred_text = decode_prediction(pred)\n",
    "        \n",
    "        # Add ✓ or ✗ to show correct/incorrect predictions\n",
    "        match = \"✓\" if pred_text == true_label else \"✗\"\n",
    "        print(f\"True: {true_label}, Predicted: {pred_text} {match}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 valid images\n",
      "Evaluating model on full test set...\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - char_0_accuracy: 0.9969 - char_0_loss: 0.0118 - char_1_accuracy: 0.9911 - char_1_loss: 0.0218 - char_2_accuracy: 0.9849 - char_2_loss: 0.0489 - char_3_accuracy: 0.9912 - char_3_loss: 0.0338 - loss: 0.1162\n",
      "Processed 100 images...\n",
      "Processed 200 images...\n",
      "Processed 300 images...\n",
      "Processed 400 images...\n",
      "Processed 500 images...\n",
      "Processed 600 images...\n",
      "Processed 700 images...\n",
      "Processed 800 images...\n",
      "Processed 900 images...\n",
      "Processed 1000 images...\n",
      "Processed 1100 images...\n",
      "Processed 1200 images...\n",
      "\n",
      "Evaluation Results:\n",
      "Character-level accuracy: 99.12%\n",
      "Full-text accuracy: 96.58%\n",
      "\n",
      "Random Test Examples:\n",
      "Image: 7MA3.png\n",
      "True: 7MA3, Predicted: 7MA3 ✓\n",
      "\n",
      "Image: 3RRR.png\n",
      "True: 3RRR, Predicted: 3RRR ✓\n",
      "\n",
      "Image: HX8T.png\n",
      "True: HX8T, Predicted: HX8T ✓\n",
      "\n",
      "Image: 8WRD.png\n",
      "True: 8WRD, Predicted: 8WRD ✓\n",
      "\n",
      "Image: 23VN.png\n",
      "True: 23VN, Predicted: 23VN ✓\n",
      "\n",
      "Image: 5ENP.png\n",
      "True: 5ENP, Predicted: 5ENP ✓\n",
      "\n",
      "Image: 8DF4.png\n",
      "True: 8DF4, Predicted: 8DF4 ✓\n",
      "\n",
      "Image: AU79.png\n",
      "True: AU79, Predicted: AU79 ✓\n",
      "\n",
      "Image: 7RW3.png\n",
      "True: 7RW3, Predicted: 7RW3 ✓\n",
      "\n",
      "Image: 29WX.png\n",
      "True: 29WX, Predicted: 29WK ✗\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def evaluate_model(model_path, test_paths, test_labels, batch_size=32):\n",
    "    \"\"\"Evaluate model accuracy on test set\"\"\"\n",
    "    # Load the model\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    # Create test generator\n",
    "    test_generator = CaptchaDataGenerator(test_paths, test_labels, batch_size)\n",
    "    \n",
    "    # Evaluate model\n",
    "    results = model.evaluate(test_generator, verbose=1)\n",
    "    \n",
    "    # Calculate character-wise and full-text accuracy\n",
    "    correct_chars = 0\n",
    "    correct_texts = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    for i in range(len(test_paths)):\n",
    "        img_path = test_paths[i]\n",
    "        true_label = test_labels[i]\n",
    "        \n",
    "        # Preprocess and predict\n",
    "        img = preprocess_image(img_path)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        pred = model.predict(img, verbose=0)\n",
    "        pred_text = decode_prediction(pred)\n",
    "        \n",
    "        # Count correct characters\n",
    "        for j in range(len(true_label)):\n",
    "            if pred_text[j] == true_label[j]:\n",
    "                correct_chars += 1\n",
    "        \n",
    "        # Count completely correct texts\n",
    "        if pred_text == true_label:\n",
    "            correct_texts += 1\n",
    "            \n",
    "        total_predictions += 1\n",
    "        \n",
    "        # Print progress\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Processed {i + 1} images...\")\n",
    "    \n",
    "    char_accuracy = correct_chars / (total_predictions * NUM_CHARS)\n",
    "    text_accuracy = correct_texts / total_predictions\n",
    "    \n",
    "    print(\"\\nEvaluation Results:\")\n",
    "    print(f\"Character-level accuracy: {char_accuracy:.2%}\")\n",
    "    print(f\"Full-text accuracy: {text_accuracy:.2%}\")\n",
    "    \n",
    "    return char_accuracy, text_accuracy\n",
    "\n",
    "# Modified model saving code (replace in your training code)\n",
    "def save_model_with_accuracy(model, val_generator, model_dir='models'):\n",
    "    \"\"\"Save model with accuracy in filename\"\"\"\n",
    "    # Evaluate model\n",
    "    results = model.evaluate(val_generator, verbose=1)\n",
    "    \n",
    "    # Calculate average accuracy across all characters\n",
    "    accuracies = [v for k, v in zip(model.metrics_names, results) if 'accuracy' in k]\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    \n",
    "    # Create model directory if it doesn't exist\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    # Save model with accuracy in filename\n",
    "    model_name = f'captcha_model_acc{avg_accuracy:.4f}.keras'\n",
    "    model_path = os.path.join(model_dir, model_name)\n",
    "    model.save(model_path)\n",
    "    print(f\"Model saved as: {model_path}\")\n",
    "    return model_path\n",
    "\n",
    "# Test script\n",
    "def test_saved_model(model_path, num_samples=10):\n",
    "    \"\"\"Test saved model on random samples\"\"\"\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    # Load your test dataset\n",
    "    data_dir = 'captcha_images_8k'  # Replace with your image directory\n",
    "    image_paths, labels = load_dataset(data_dir)\n",
    "    \n",
    "    # Split into train/val/test sets\n",
    "    train_paths, temp_paths, train_labels, temp_labels = train_test_split(\n",
    "        image_paths, labels, test_size=0.3, random_state=42\n",
    "    )\n",
    "    val_paths, test_paths, val_labels, test_labels = train_test_split(\n",
    "        temp_paths, temp_labels, test_size=0.5, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Evaluate on full test set\n",
    "    print(\"Evaluating model on full test set...\")\n",
    "    char_accuracy, text_accuracy = evaluate_model(model_path, test_paths, test_labels)\n",
    "    \n",
    "    # Show some random examples\n",
    "    print(\"\\nRandom Test Examples:\")\n",
    "    for i in range(num_samples):\n",
    "        idx = np.random.randint(len(test_paths))\n",
    "        img_path = test_paths[idx]\n",
    "        true_label = test_labels[idx]\n",
    "        \n",
    "        # Make prediction\n",
    "        img = preprocess_image(img_path)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        pred = model.predict(img, verbose=0)\n",
    "        pred_text = decode_prediction(pred)\n",
    "        \n",
    "        match = \"✓\" if pred_text == true_label else \"✗\"\n",
    "        print(f\"Image: {os.path.basename(img_path)}\")\n",
    "        print(f\"True: {true_label}, Predicted: {pred_text} {match}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your model path\n",
    "    model_path = 'best_captcha_model_20241207_141820.keras'\n",
    "    test_saved_model(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
